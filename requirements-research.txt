# RC-Mamba Research Dependencies
# Core ML/DL frameworks
torch>=2.0.0
transformers>=4.35.0
tokenizers>=0.15.0
datasets>=2.14.0
accelerate>=0.24.0

# Mamba and state space models
mamba-ssm>=1.2.0
causal-conv1d>=1.1.0

# Retrieval and similarity search
faiss-cpu>=1.7.4
faiss-gpu>=1.7.4  # Use faiss-gpu if CUDA available
sentence-transformers>=2.2.2
chromadb>=0.4.0

# Multimodal processing
opencv-python>=4.8.0
pillow>=10.0.0
librosa>=0.10.0
soundfile>=0.12.0
torchaudio>=2.0.0
torchvision>=0.15.0

# Audio processing
speechbrain>=0.5.15
whisper>=1.1.10

# Training and optimization
peft>=0.6.0  # Parameter Efficient Fine-tuning
bitsandbytes>=0.41.0
deepspeed>=0.10.0
wandb>=0.15.0
tensorboard>=2.14.0

# Data processing and utilities
numpy>=1.24.0
pandas>=2.0.0
scipy>=1.11.0
scikit-learn>=1.3.0
einops>=0.7.0
tqdm>=4.65.0

# Evaluation and metrics
rouge-score>=0.1.2
sacrebleu>=2.3.1
nltk>=3.8.1
evaluate>=0.4.0

# Quantization and compression
optimum>=1.13.0
auto-gptq>=0.4.2

# Configuration and logging
hydra-core>=1.3.0
omegaconf>=2.3.0
loguru>=0.7.0
rich>=13.0.0

# Mathematical and scientific computing
sympy>=1.12.0
networkx>=3.1.0

# Plotting and visualization
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.15.0

# Document processing and LaTeX
pylatex>=1.19.0
jinja2>=3.1.0

# Testing and development
pytest>=7.4.0
pytest-cov>=4.1.0
black>=23.7.0
isort>=5.12.0
flake8>=6.0.0
mypy>=1.5.0
pre-commit>=3.3.0

# Optional: Cloud and deployment
boto3>=1.28.0
google-cloud-storage>=2.10.0
docker>=6.1.0

# Optional: Distributed training
torch-distributed>=0.3.0
horovod>=0.28.0

# Optional: Profiling and debugging
py-spy>=0.3.14
memory-profiler>=0.61.0
line-profiler>=4.1.0

# Optional: Jupyter and interactive development
jupyter>=1.0.0
ipywidgets>=8.1.0
notebook>=7.0.0

# Version constraints for compatibility
setuptools>=65.0.0
wheel>=0.41.0
pip>=23.0.0
